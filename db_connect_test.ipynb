import tensorflow as tf
import pandas as pd
import pymysql
from sklearn.preprocessing import RobustScaler
import numpy as np
import time
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime

# 구글 시트 연결 설정
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_name("my_cred.json", scope)
client = gspread.authorize(creds)
sheet = client.open("Fire Prediction Log").sheet1  # 첫 번째 시트 사용

# 모델 불러오기
model = tf.keras.models.load_model('fire_anomaly_model.h5')

# DB 연결
def dbconnect():
    return pymysql.connect(
        host='localhost',
        port=3306,
        user='test1',
        password='P@ssw0rd',
        db='test',
        charset='utf8'
    )

# 데이터 로드 및 전처리
def fetch_data(conn):
    query = "SELECT * FROM sensor_data"
    df = pd.read_sql(query, conn)
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
    df = df.sort_values('Date').reset_index(drop=True)

    features = ['CO_Room', 'Temperature_Room', 'Humidity_Room', 'PM10_Room']
    df = df.dropna(subset=features)
    df['CO_Room'] = df['CO_Room'].clip(lower=0)

    return df, features

# 시퀀스 생성
def create_sequences(df, features, window_size=60):
    scaler = RobustScaler()
    X_scaled = scaler.fit_transform(df[features])
    X_seq = []
    for i in range(len(X_scaled) - window_size):
        X_seq.append(X_scaled[i:i + window_size])
    return np.array(X_seq)

# 시트에 예측 로그 기록
def log_to_sheet(index, prob, label):
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    sheet.append_row([now, index, round(prob, 4), "경고" if label == 1 else "정상"])

# 시트에 경고 시 원본 데이터 기록
def log_window_data(window_df):
    sheet.append_row(["--- 최근 60개 센서값 (경고 발생 시점) ---"])
    sheet.append_row(["Date", "CO_Room", "Temperature_Room", "Humidity_Room", "PM10_Room"])
    for _, row in window_df.iterrows():
        sheet.append_row([
            row['Date'].strftime("%Y-%m-%d %H:%M:%S"),
            row['CO_Room'], row['Temperature_Room'],
            row['Humidity_Room'], row['PM10_Room']
        ])

# 전체 데이터 불러오기
conn = dbconnect()
df, features = fetch_data(conn)
conn.close()

# 시퀀스 생성
X_seq = create_sequences(df, features)

print(f"총 시퀀스 개수: {len(X_seq)}\n시뮬레이션 시작...")

for i in range(len(X_seq)):
    input_seq = X_seq[i].reshape(1, 60, 4)
    prob = model.predict(input_seq, verbose=0)[0][0]
    label = int(prob > 0.8)

    # 콘솔 출력
    print(f"[{i+1}/{len(X_seq)}] 🔥 화재 확률: {prob:.4f} → {'🚨 경고' if label == 1 else '✅ 정상'}")

    # 구글 시트 기록
    log_to_sheet(i+1, prob, label)

    if label == 1:
        print("\n🚨 경고 발생 시점의 원본 데이터 (최근 60개):")
        window_df = df.iloc[i:i+60][['Date'] + features]
        print(window_df.tail(60))
        log_window_data(window_df)

    time.sleep(1)  # 1초 간격 유지
